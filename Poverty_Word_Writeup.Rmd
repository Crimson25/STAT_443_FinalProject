---
title: "Final Project"
author: "Kiera Grant, Braden Barglind, and Colin Fitzpatrick"
date: "12/4/2020"
output:
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
The objective of this study is to determine an appropriate logistic regression model in order to classify individuals into one of four poverty levels. Many social programs have a hard time making sure the right people are given enough aid. Often times the poorest of the population might not be given enough aid because they typically cannot provide the necessary income and expense records to prove that they qualify. Instead, this study will consider a familyâ€™s observable household attributes such as the material of their walls and ceiling, or the assets found in the home, to classify poverty levels. The original dataset contains survey responses from 9,057 individuals with 142 predictor variables. For purposes of this study, only data from the "heads of household" will be used which focuses the data down to 2,819 observations. 

In order to find a sufficient model, all of the predictor variables will be assessed for repetitiveness and skewness and potentially transformed. Relationships between predictor variables and poverty level as well as between the different predictor variables will need to be evaluated. This will help determine any preliminary multicollinearity issues so that these variables can be removed from the dataset early. The data will be split into a training data set as well as a validation data set in order to test the accuracy of our model. A logistic regression model will be created using the training data. The model will then be used to predict the poverty level of samples to determine the effectiveness of the model. The model selection tools will be used to determine if more accuracy is gained through a new model. Next, the classification threshold will be investigated to determine which value optimizes accuracy. The final model will be determined based off of these analyses in hopes to have an appropriate model to classify individuals into a poverty class. 

## Exploring and Transforming the Data
The first thing that we had to take care of, was limiting the amount of variables to a sizable amount.  We then deleted all redundant variables which measured the same things but called by different names.  An example of this is these redundant variables hhsize and tamhog, which both measure the size of the household.  So we are able to get rid of one of them and keep the other.  Another thing we did with the data is to combine some of the terms so that we would have one variable that was now a binomial response. An example of this is, there was a male and female tab, which we are able to remove one of them because it gives redundant information.  Another way we partioned through the data was to get rid of variables based in the percentage of reponses that they had.  For example, one of the identifiers was if the house had a bathroom or not and the probability of houses having a bathroom was .995.  This results in a bad predictor as too many people have a bathroom so it is not a good predictor in that since.  So after those three ideas took place we were left with 34 variables left out of 142.
```{r message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}
library(tidyverse) 
library(ggrepel) 
library(kableExtra) 
library(RColorBrewer) 
library(corrplot) 
library(caret) 
library(e1071) 
library(dominanceanalysis) 
library("readxl")

project_data <-  read_excel("HeadOfHouseHoldFile.xlsx")
head(project_data)

project_data2 <- read_excel("HeadOfHouseHoldFileUpdate.xlsx")
head(project_data2)

project_data_final <- read_excel("FinalChanges.xlsx")
head(project_data_final)

##CLEAN UP DATA
#replaces one variable with the variable that was transformed
project_data_final$tamviv <- project_data_final$tamvivsqrt
names(project_data_final)[3] <- "tamviv_sqrt"

#removes reference variables (and removes copy of transformed variable)
project_data_final <- project_data_final %>% dplyr::select(-c("paredblolad","paredpreb", "energcocinar2", "energcocinar3", "Married/Free Coupled", "div,sep,wid", "single", "parentesco1","tamvivsqrt"))

project_data_final$Target <- as.factor(project_data_final$Target) # sets Target to factor for analyses
apply(is.na(project_data_final), 2, which) #detects NAs in data frame, 3 values in meaneduc (1287, 1400, 1455), 1 value in depend (1287)
project_data_final[is.na(project_data_final)]=0  #replaces NAs with 0, can replace with zero for these categories


##EXPLORING THE DATA - QUANTITATIVE
#Rooms Plot (normal)
roomcounts <- table(project_data$rooms)
barplot(roomcounts,main="Number of Rooms", xlab="Room Counts")

#Number of Tablets Plot (heavy skew right)
tabletscounts <- table(project_data$v18q1)
barplot(tabletscounts,main="Number of Tablets", xlab="Tablet Counts")

#Number of People in Household Plot (skew right)
peoplecounts <- table(project_data$tamviv)
barplot(peoplecounts, main="Number of People in Household", xlab="People Counts")

#Children 0-19 Plot (skew right)
childrencounts <- table(project_data$hogar_nin)
barplot(childrencounts, main="Number of Children 0-19", xlab="Children Counts")

#Number of Adults Plot (small skew right)
adultcounts <- table(project_data$hogar_adul)
barplot(adultcounts, main="Number of Adults", xlab="Adult Counts")

#People 65+ Plot (heavy skew right)
people65counts <- table(project_data$hogar_mayor)
barplot(people65counts, main="People 65+", xlab = "People Counts")

#EdJefe Plot (weird)
edjefecounts <- table(project_data$edjefe)
barplot(edjefecounts, main="Ed Jefe Counts", xlab = "Counts")

#EdJefa Plot (weird)
edjefacounts <- table(project_data$edjefa)
barplot(edjefacounts, main="Ed Jefa Counts", xlab="Counts")

#Mean Education Plot (weird)
meaneducounts <- table(project_data$meaneduc)
barplot(meaneducounts, main="Mean Education", xlab="Counts")

#Overcrowding Plot (weird)
overcrowdcounts <- table(project_data$overcrowding)
barplot(overcrowdcounts, main="Overcrowding", xlab="Counts")

#Number of Dependents (weird)
dependcounts <- table(project_data$depend)
barplot(dependcounts, main="Dependencies", xlab="Counts")


##TRANSFORMATIONS
#Number of people in Household transformation: Square root  (only transformation that showed significant change)
sqrttamviv <- (sqrt(project_data$tamviv))
hist(sqrttamviv)


##EXPLORING RELATIONSHIPS

#Relationships between predictors
quantvars <- c(1,2,3,13,14,15,16,17,18,19,22,25)
dichotomouscategorvars <- c(4,5,6,7,8,9,10,11,20,21,23) #12=marriage status, has 3 levels
categorvars <- c(4,5,6,7,8,9,10,11,12,20,21,23)

#shows top correlated variables
z <-cor(project_data_final[,quantvars])
z[lower.tri(z,diag=TRUE)]=NA 
z2=as.data.frame(as.table(z))  
z3=na.omit(z2) 
z4 <- subset(z3, abs(Freq)> .5) 
correlation_df <- z4[order(-z4$Freq), ]
correlation_df

library(PerformanceAnalytics)
chart.Correlation(project_data_final[,quantvars],histogram = TRUE) #correlations for quantitative variables
chart.Correlation(project_data_final[,dichotomouscategorvars],histogram = TRUE) #correlations for dichotomous categorical variables
chart.Correlation(project_data_final[,categorvars],histogram = TRUE, method = "spearman") #correlations for categorical variables
catvartest<- chisq.test()   #pairwise, double "for" loop

#Relationships between predictors and response variables
library(gridExtra)
##Function for creating bar graphs (of all quantitative variables) by target
graphs <- function(x){
xvar <- unlist(project_data_final[,x])
plot <- project_data_final %>% ggplot(aes(xvar,fill=Target))+ 
  geom_bar() + 
  facet_grid(. ~ Target) +
  xlab(colnames(project_data_final[x]))
return(plot)
}
plot_list <-lapply(quantvars,FUN=graphs)
plot_list


##Function for creating FREQUENCY graphs (of all quantitative variables) by target
freqgraphs <- function(x){
xvar <- unlist(project_data_final[,x])
plot <- project_data_final %>% ggplot(aes(xvar, colour=Target)) + 
  geom_freqpoly(aes(group = Target)) +
  xlab(colnames(project_data_final[x]))
return(plot)
}
freqplot_list <-lapply(quantvars,FUN=freqgraphs)
freqplot_list

```


## The Statistical Model
Our ideal model would be a model that optimizes overall accuracy, in which it would accurately predict the level of income for an individual
and family. The accuracy of the model is important, as it will help social programs and the government decide who needs financial support, and how much 
of it. We used many different techniques of modeling the data. Trying numerous methods and models helped us choose the one that optimized overall accuracy. The logistic regression models used included regression using all the variables, a VIF based model, Lasso, Ridge, Backward Selection, Forward Selection, Best Subsets model, Best BIC model, adjusted R-squared, and two different ordinal regression models, along with a SVM model that ended up being our most accurate of all the proposed models. On top of evaluating the overall accuracies for the models, we summarized the sensitivities and specificities for each model in order to get a better understanding of the predictive power for each model, and exactly what they are telling us. Our data comprised of many different types of variables that tried to predictpoverty levels. We attacked the study by using multiple models, as stated previously, and the following will dive deeper into each model.

By running a full model, we got a grasp and beginners understanding on how each variable impacted the predictive power of income levels. By looking at the p-values, it was noteworthy that there potentially were insignificant variables that needed to be excluded, and/or the fact that there was multicollinearity we had to fix. In order to do this, we took the approach of running forward and backwards selection, in which each eliminates insignificant variables from the model from their respective direction in the process. To deal with multicollinearity, we had to execute a model in which showed us the VIF values. In the statistical world, the general rule of thumb is that multicollinearity exists within variables that have a VIF of ten or greater. So, our group deleted the few variables that did possess VIF of ten or higher, and ran the modelin hopes of a better accuracy. Also to help fix multicollinearity, we built a ridge regression model. On top of these models, we ran two different ordinal models that are similar to a normal general linear model estimation. We decided on ordinal regression being a plausable model to attempt because the dependent variablewas in an ordered fashion, with 1 being very poor and 4 being wealthy, and everything in between. Also seen below is lasso regression, which performed both variable selection andregularization in order to produce a model similar to a linear regression model. Two more models attempted were the best subsets model and highest adjusted R-squared model. For the best subsets method, the chosen model was the one that had the lowest AIC (Akaike Information Criterion). This is similar to the adjusted R-squared model, in which instead of having the lowest AIC, we chose the one with the highest adjusted R-squared value, where we attempt to be able to explain as much as we can when relating the poverty levels to each independent variable. Lastly, we used a Support Vector Machine to create a model. SVM's are supervised learning models with associated learning algorithms that analyze data used for classificiation and regression analysis. The code shows our work and model selection process, along with a table showing the overall accuracies for each model attempted. 
```{r message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}

#split data into raining and testing set
set.seed(46217921)
train.pov <- sample(1:nrow(project_data_final), floor(.75*nrow(project_data_final)), replace=F)
dat.tr <- project_data_final[train.pov,]
dat.te <- project_data_final[-train.pov,]
head(dat.tr)
table(dat.tr$Target) #.66556 proportions are target 4
table(dat.te$Target) #.626995 proportions are target 4


library(nnet)
library(MLmetrics)
library(compositions)
library(caret)

#Build regression model using training/testing
mod.full <- multinom(Target ~ ., data=dat.tr) #Multinom Function

#gives VIF values of each variable in the full model: want to remove variables with VIF higher than 5-10, for this analyses the following remain after removing higher than 10: v18q1,CementorBetter, cielorazo, epared1, etecho1, eviv1, dis, computer, television, area1
car::vif(mod.full)

#Finds pseudo R^2 value of model
library(DescTools)
PseudoR2(mod.full,"McFadden") # R^2 = .227

#ACCURACY OF TRAINING DATA - Full Multinomial Model = .702
predicted_classFM_TR <- predict(mod.full,dat.tr)
caret::confusionMatrix(as.factor(predicted_classFM_TR),as.factor(dat.tr$Target))

#ACCURACY OF TESTING DATA - Full Multinomial Model= .634
predicted_classFM_TE <- predict(mod.full,dat.te)
caret::confusionMatrix(as.factor(predicted_classFM_TE),as.factor(dat.te$Target))

#SENSITIVITIES, SPECIFICITIES, AND AUC TRAINING DATA - FUll Multinomial Model
dat_roc_FM_TR<- data.frame(T1_true = numeric(2114),T2_true= numeric(2114),T3_true= numeric(2114),T4_true= numeric(2114),T1_pred_FM= numeric(2114),T2_pred_FM= numeric(2114),T3_pred_FM= numeric(2114),T4_pred_FM= numeric(2114))
#creates data frame in form needed for multi_roc function
dat_roc_FM_TR$T1_true <- ifelse(dat.tr$Target == 1, 1, 0)
dat_roc_FM_TR$T2_true <- ifelse(dat.tr$Target == 2, 1, 0)
dat_roc_FM_TR$T3_true <- ifelse(dat.tr$Target == 3, 1, 0)
dat_roc_FM_TR$T4_true <- ifelse(dat.tr$Target == 4, 1, 0)
dat_roc_FM_TR$T1_pred_FM <- ifelse(predicted_classFM_TR == 1, 1, 0)
dat_roc_FM_TR$T2_pred_FM <- ifelse(predicted_classFM_TR == 2, 1, 0)
dat_roc_FM_TR$T3_pred_FM <- ifelse(predicted_classFM_TR == 3, 1, 0)
dat_roc_FM_TR$T4_pred_FM <- ifelse(predicted_classFM_TR == 4, 1, 0)

#micro value training data = .7713
rocfit.full_FM_TR <- multi_roc(dat_roc_FM_TR)
rocfit.full_FM_TR$AUC


#SENSITIVITIES, SPECIFICITIES, AND AUC TESTING DATA - FUll Multinomial Model
dat_roc_FM_TE<- data.frame(T1_true = numeric(705),T2_true= numeric(705),T3_true= numeric(705),T4_true= numeric(705),T1_pred_FM= numeric(705),T2_pred_FM= numeric(705),T3_pred_FM= numeric(705),T4_pred_FM= numeric(705))
#creates data frame in form needed for multi_roc function
dat_roc_FM_TE$T1_true <- ifelse(dat.te$Target == 1, 1, 0)
dat_roc_FM_TE$T2_true <- ifelse(dat.te$Target == 2, 1, 0)
dat_roc_FM_TE$T3_true <- ifelse(dat.te$Target == 3, 1, 0)
dat_roc_FM_TE$T4_true <- ifelse(dat.te$Target == 4, 1, 0)
dat_roc_FM_TE$T1_pred_FM <- ifelse(predicted_classFM_TE == 1, 1, 0)
dat_roc_FM_TE$T2_pred_FM <- ifelse(predicted_classFM_TE == 2, 1, 0)
dat_roc_FM_TE$T3_pred_FM <- ifelse(predicted_classFM_TE == 3, 1, 0)
dat_roc_FM_TE$T4_pred_FM <- ifelse(predicted_classFM_TE == 4, 1, 0)

#micro value testing data= .7280
rocfit.full_FM_TE <- multi_roc(dat_roc_FM_TE)
rocfit.full_FM_TE$AUC




##Multinomial Model #2
mod.vif_under_10 <-multinom(Target~v18q1 + CementorBetter + cielorazo + epared1 + etecho1 + eviv1 + dis + computer + television + area1, data = dat.tr)

car::vif(mod.vif_under_10)
PseudoR2(mod.vif_under_10,"all") # R^2 = .1026

#ACCURACY OF TRAINING DATA - VIF Under 10 Multinomial Model = .6712
predicted_classFM2_TR <- predict(mod.vif_under_10,dat.tr)
caret::confusionMatrix(as.factor(predicted_classFM2_TR),as.factor(dat.tr$Target))

#ACCURACY OF TESTING DATA - VIF Under 10 Multinomial Model= .6241
predicted_classFM2_TE <- predict(mod.vif_under_10,dat.te)
caret::confusionMatrix(as.factor(predicted_classFM2_TE),as.factor(dat.te$Target))

#SENSITIVITIES, SPECIFICITIES, AND AUC TRAINING DATA- Multinomial Model #2
dat_roc_FM2_TR<- data.frame(T1_true = numeric(2114),T2_true= numeric(2114),T3_true= numeric(2114),T4_true= numeric(2114),T1_pred_FM2= numeric(2114),T2_pred_FM2= numeric(2114),T3_pred_FM2= numeric(2114),T4_pred_FM2= numeric(2114))
#creates data frame in form needed for multi_roc function
dat_roc_FM2_TR$T1_true <- ifelse(dat.tr$Target == 1, 1, 0)
dat_roc_FM2_TR$T2_true <- ifelse(dat.tr$Target == 2, 1, 0)
dat_roc_FM2_TR$T3_true <- ifelse(dat.tr$Target == 3, 1, 0)
dat_roc_FM2_TR$T4_true <- ifelse(dat.tr$Target == 4, 1, 0)
dat_roc_FM2_TR$T1_pred_FM2 <- ifelse(predicted_classFM2_TR == 1, 1, 0)
dat_roc_FM2_TR$T2_pred_FM2 <- ifelse(predicted_classFM2_TR == 2, 1, 0)
dat_roc_FM2_TR$T3_pred_FM2 <- ifelse(predicted_classFM2_TR == 3, 1, 0)
dat_roc_FM2_TR$T4_pred_FM2 <- ifelse(predicted_classFM2_TR == 4, 1, 0)

#micro value training data = .7562
rocfit.full_FM2_TR <- multi_roc(dat_roc_FM2_TR)
rocfit.full_FM2_TR$AUC

#SENSITIVITIES, SPECIFICITIES, AND AUC TESTING DATA - Multinomial Model #2
dat_roc_FM2_TE<- data.frame(T1_true = numeric(705),T2_true= numeric(705),T3_true= numeric(705),T4_true= numeric(705),T1_pred_FM2= numeric(705),T2_pred_FM2= numeric(705),T3_pred_FM2= numeric(705),T4_pred_FM2= numeric(705))
#creates data frame in form needed for multi_roc function
dat_roc_FM2_TE$T1_true <- ifelse(dat.te$Target == 1, 1, 0)
dat_roc_FM2_TE$T2_true <- ifelse(dat.te$Target == 2, 1, 0)
dat_roc_FM2_TE$T3_true <- ifelse(dat.te$Target == 3, 1, 0)
dat_roc_FM2_TE$T4_true <- ifelse(dat.te$Target == 4, 1, 0)
dat_roc_FM2_TE$T1_pred_FM2 <- ifelse(predicted_classFM2_TE == 1, 1, 0)
dat_roc_FM2_TE$T2_pred_FM2 <- ifelse(predicted_classFM2_TE == 2, 1, 0)
dat_roc_FM2_TE$T3_pred_FM2 <- ifelse(predicted_classFM2_TE == 3, 1, 0)
dat_roc_FM2_TE$T4_pred_FM2 <- ifelse(predicted_classFM2_TE == 4, 1, 0)

#micro value testing data = .7252
rocfit.full_FM2_TE <- multi_roc(dat_roc_FM2_TE)
rocfit.full_FM2_TE$AUC
```

```{r}
#Cumulative Logit Model - Reflects ordering - NOT WORKING
library(VGAM)
fit.adj <- vglm(Target ~ .,family=cumulative(parallel=TRUE), data=dat.tr)
coef(fit.adj)
predict.te <- predict(fit.adj,dat.te, type = "response")

#ACCURACY OF TRAINING DATA =
predicted_classVGLM <- predict(fit.adj,dat.tr)
caret::confusionMatrix(as.factor(predicted_classVGLM),as.factor(dat.tr$Target))

#ACCURACY OF TESTING DATA =
predicted_classVGLM <- predict(mod.full,dat.te)
caret::confusionMatrix(as.factor(predicted_classML),as.factor(dat.te$Target))
```

```{r}
#LASSO MODEL  - suggests to take out hogar_nin and edjefa
library(glmnet)
xx <- model.matrix(Target~., dat.tr)
yy <- as.integer(dat.tr$Target) #packages requires this to be numeric
lasso.out <- cv.glmnet(xx, yy, alpha=1, family = "multinomial", type.multinomial = "grouped", type.measure="class")  #do we need to set this family to multinomial?
coef(lasso.out, s=lasso.out$lambda.min)

#ACCURACY OF TRAINING DATA = .6977
mod.lasso.tr <- multinom(formula = Target ~ rooms + v18q1 + tamviv + CementorBetter + cielorazo + GasOrElectric + elimbasu1 + epared1 + etecho1 + eviv1 + dis + comMSS + hogar_adul + hogar_mayor + edjefe + meaneduc + overcrowding + computer + television + qmobilephone + area1 + depend, data = dat.tr)
predicted_classLM_TR <- predict(mod.lasso.tr, type="class")
acc_LM_TR <- caret::confusionMatrix(as.factor(predicted_classLM_TR),as.factor(dat.tr$Target))

#ACCURACY OF Testing DATA = .6723
mod.lasso.te <- multinom(formula = Target ~ rooms + v18q1 + tamviv + CementorBetter + cielorazo + GasOrElectric + elimbasu1 + epared1 + etecho1 + eviv1 + dis + comMSS + hogar_adul + hogar_mayor + edjefe + meaneduc + overcrowding + computer + television + qmobilephone + area1 + depend, data = dat.te)
predicted_classLM_TE <- predict(mod.lasso.te, type="class")
acc_LM_TE <- caret::confusionMatrix(as.factor(predicted_classLM_TE),as.factor(dat.te$Target))

#SENSITIVITIES, SPECIFICITIES, AND AUC TRAINING DATA - LASSO MODEL
dat_roc_tr_LM <- data.frame(T1_true = numeric(2114),T2_true= numeric(2114),T3_true= numeric(2114),T4_true= numeric(2114),T1_pred_LM= numeric(2114),T2_pred_LM= numeric(2114),T3_pred_LM= numeric(2114),T4_pred_LM= numeric(2114))
#creates data frame in form needed for multi_roc function
dat_roc_tr_LM$T1_true <- ifelse(dat.tr$Target == 1, 1, 0)
dat_roc_tr_LM$T2_true <- ifelse(dat.tr$Target == 2, 1, 0)
dat_roc_tr_LM$T3_true <- ifelse(dat.tr$Target == 3, 1, 0)
dat_roc_tr_LM$T4_true <- ifelse(dat.tr$Target == 4, 1, 0)
dat_roc_tr_LM$T1_pred_LM <- ifelse(predicted_classLM_TR == 1, 1, 0)
dat_roc_tr_LM$T2_pred_LM <- ifelse(predicted_classLM_TR == 2, 1, 0)
dat_roc_tr_LM$T3_pred_LM <- ifelse(predicted_classLM_TR == 3, 1, 0)
dat_roc_tr_LM$T4_pred_LM <- ifelse(predicted_classLM_TR == 4, 1, 0)

#micro value training data = .7664
rocfit.full_tr_LM<- multi_roc(dat_roc_tr_LM)
rocfit.full_tr_LM$AUC

#SENSITIVITIES, SPECIFICITIES, AND AUC TESTING DATA - LASSO MODEL
dat_roc_te_LM <- data.frame(T1_true = numeric(705),T2_true= numeric(705),T3_true= numeric(705),T4_true= numeric(705),T1_pred_LM= numeric(705),T2_pred_LM= numeric(705),T3_pred_LM= numeric(705),T4_pred_LM= numeric(705))
#creates data frame in form needed for multi_roc function
dat_roc_te_LM$T1_true <- ifelse(dat.te$Target == 1, 1, 0)
dat_roc_te_LM$T2_true <- ifelse(dat.te$Target == 2, 1, 0)
dat_roc_te_LM$T3_true <- ifelse(dat.te$Target == 3, 1, 0)
dat_roc_te_LM$T4_true <- ifelse(dat.te$Target == 4, 1, 0)
dat_roc_te_LM$T1_pred_LM <- ifelse(predicted_classLM_TE == 1, 1, 0)
dat_roc_te_LM$T2_pred_LM <- ifelse(predicted_classLM_TE == 2, 1, 0)
dat_roc_te_LM$T3_pred_LM <- ifelse(predicted_classLM_TE == 3, 1, 0)
dat_roc_te_LM$T4_pred_LM <- ifelse(predicted_classLM_TE == 4, 1, 0)

#micro value testing data = .7537
rocfit.full_te_LM<- multi_roc(dat_roc_te_LM)
rocfit.full_te_LM$AUC
```

```{r}
#Ridge MODEL  - doesn't suggest to take any variables out?
xxR <- model.matrix(Target~., dat.tr)
yyR <- as.integer(dat.tr$Target) #packages requires this to be numeric
ridge.out <- cv.glmnet(xxR, yyR, alpha=0, type.measure="class") 
coef(ridge.out, s=ridge.out$lambda.min)

#same accuracies as full multinomial model?
#Training Accuracy = .702
#Testing Accuracy = .634
#same micro values of full multinomial model? = training=  .7713    testing = .7280

```

```{r}
#Backward Selection - significant variables in equation below
#multinom(formula = Target ~ v18q1 + tamviv + CementorBetter + cielorazo + GasOrElectric + etecho1 + eviv1 + dis + hogar_mayor + edjefe + meaneduc + television + qmobilephone + area1 + depend, data = dat.tr)
mod.back <- step(mod.full,  direction="backward", trace=0)
summary(mod.back)

#ACCURACY OF TRAINING DATA = .7006
predicted_classBS_TR <- predict(mod.back,dat.tr)
caret::confusionMatrix(as.factor(predicted_classBS_TR),as.factor(dat.tr$Target))

#ACCURACY OF TESTING DATA = .6426
predicted_classBS_TE <- predict(mod.back,dat.te)
caret::confusionMatrix(as.factor(predicted_classBS_TE),as.factor(dat.te$Target))

#SENSITIVITIES, SPECIFICITIES, AND AUC TRAINING DATA - Backwards Selection Model
dat_roc_BS_TR<- data.frame(T1_true = numeric(2114),T2_true= numeric(2114),T3_true= numeric(2114),T4_true= numeric(2114),T1_pred_BS= numeric(2114),T2_pred_BS= numeric(2114),T3_pred_BS= numeric(2114),T4_pred_BS= numeric(2114))
#creates data frame in form needed for multi_roc function
dat_roc_BS_TR$T1_true <- ifelse(dat.tr$Target == 1, 1, 0)
dat_roc_BS_TR$T2_true <- ifelse(dat.tr$Target == 2, 1, 0)
dat_roc_BS_TR$T3_true <- ifelse(dat.tr$Target == 3, 1, 0)
dat_roc_BS_TR$T4_true <- ifelse(dat.tr$Target == 4, 1, 0)
dat_roc_BS_TR$T1_pred_BS <- ifelse(predicted_classBS_TR == 1, 1, 0)
dat_roc_BS_TR$T2_pred_BS <- ifelse(predicted_classBS_TR == 2, 1, 0)
dat_roc_BS_TR$T3_pred_BS <- ifelse(predicted_classBS_TR == 3, 1, 0)
dat_roc_BS_TR$T4_pred_BS <- ifelse(predicted_classBS_TR == 4, 1, 0)

#micro value training data = .7700
rocfit.full_BS_TR <- multi_roc(dat_roc_BS_TR)
rocfit.full_BS_TR$AUC

#SENSITIVITIES, SPECIFICITIES, AND AUC TESTING DATA - Backwards Selection Model
dat_roc_BS_TE<- data.frame(T1_true = numeric(705),T2_true= numeric(705),T3_true= numeric(705),T4_true= numeric(705),T1_pred_BS= numeric(705),T2_pred_BS= numeric(705),T3_pred_BS= numeric(705),T4_pred_BS= numeric(705))
#creates data frame in form needed for multi_roc function
dat_roc_BS_TE$T1_true <- ifelse(dat.te$Target == 1, 1, 0)
dat_roc_BS_TE$T2_true <- ifelse(dat.te$Target == 2, 1, 0)
dat_roc_BS_TE$T3_true <- ifelse(dat.te$Target == 3, 1, 0)
dat_roc_BS_TE$T4_true <- ifelse(dat.te$Target == 4, 1, 0)
dat_roc_BS_TE$T1_pred_BS <- ifelse(predicted_classBS_TE == 1, 1, 0)
dat_roc_BS_TE$T2_pred_BS <- ifelse(predicted_classBS_TE == 2, 1, 0)
dat_roc_BS_TE$T3_pred_BS <- ifelse(predicted_classBS_TE == 3, 1, 0)
dat_roc_BS_TE$T4_pred_BS <- ifelse(predicted_classBS_TE == 4, 1, 0)

#micro value testing data = .7327
rocfit.full_BS_TE <- multi_roc(dat_roc_BS_TE)
rocfit.full_BS_TE$AUC
```

```{r}
#Forward Selection - didn't remove any variables? Equation below
#multinom(formula = Target ~ rooms + v18q1 + tamviv + CementorBetter + cielorazo + GasOrElectric + elimbasu1 + epared1 + etecho1 + eviv1 + dis + comMSS + hogar_nin + hogar_adul + hogar_mayor + edjefe + edjefa + meaneduc + overcrowding + computer + television + qmobilephone + area1 + depend, data = dat.tr)
mod.forward <- step(mod.full, direction="forward", trace=0)
test <- predict(mod.forward, type="class")
summary(mod.forward)

#ACCURACY OF TRAINING DATA = .702
predicted_classFS_TR <- predict(mod.forward,dat.tr)
caret::confusionMatrix(as.factor(predicted_classFS_TR),as.factor(dat.tr$Target))

#ACCURACY OF TESTING DATA = .634
predicted_classFS_TE <- predict(mod.forward,dat.te)
caret::confusionMatrix(as.factor(predicted_classFS_TE),as.factor(dat.te$Target))

#same micro values of full multinomial model? = training=  .7713    testing = .7280
```

```{r}
#REGSUBSETS METHOD
library(leaps)
subsets <- regsubsets(Target ~ . , data = dat.tr, nbest = 1, nvmax = NULL, force.in = NULL, force.out = NULL, method = "exhaustive") 
summary.out <- summary(subsets)  
which.max(summary.out$adjr2) 
which.min(summary.out$bic) 

##BEST ADJ R^2 MODEL
summary.out$which[17,]

#ACCURACY OF TRAINING DATA = .6987
mod.adjr2.tr <- multinom(formula = Target ~ v18q1 + CementorBetter + tamviv_sqrt + cielorazo + GasOrElectric + elimbasu1 + epared1 + etecho1 + dis + hogar_adul + hogar_mayor + edjefe + meaneduc + television + qmobilephone + area1 + depend, data = dat.tr)
predicted_classAR2_TR <- predict(mod.adjr2.tr, type="class")
caret::confusionMatrix(as.factor(predicted_classAR2_TR),as.factor(dat.tr$Target))

#ACCURACY OF Testing DATA = .6667
mod.adjr2.te <- multinom(formula = Target ~ v18q1 + CementorBetter + tamviv_sqrt + cielorazo + GasOrElectric + elimbasu1 + epared1 + etecho1 + dis + hogar_adul + hogar_mayor + edjefe + meaneduc + television + qmobilephone + area1 + depend, data = dat.te)
predicted_classAR2_TE <- predict(mod.adjr2.te, type="class")
caret::confusionMatrix(as.factor(predicted_classAR2_TE),as.factor(dat.te$Target))

#SENSITIVITIES, SPECIFICITIES, AND AUC TRAINING DATA - BEST ADJ R^2 MODEL
dat_roc_tr_AR2 <- data.frame(T1_true = numeric(2114),T2_true= numeric(2114),T3_true= numeric(2114),T4_true= numeric(2114),T1_pred_AR2= numeric(2114),T2_pred_AR2= numeric(2114),T3_pred_AR2= numeric(2114),T4_pred_AR2= numeric(2114))
#creates data frame in form needed for multi_roc function
dat_roc_tr_AR2$T1_true <- ifelse(dat.tr$Target == 1, 1, 0)
dat_roc_tr_AR2$T2_true <- ifelse(dat.tr$Target == 2, 1, 0)
dat_roc_tr_AR2$T3_true <- ifelse(dat.tr$Target == 3, 1, 0)
dat_roc_tr_AR2$T4_true <- ifelse(dat.tr$Target == 4, 1, 0)
dat_roc_tr_AR2$T1_pred_AR2 <- ifelse(predicted_classAR2_TR == 1, 1, 0)
dat_roc_tr_AR2$T2_pred_AR2 <- ifelse(predicted_classAR2_TR == 2, 1, 0)
dat_roc_tr_AR2$T3_pred_AR2 <- ifelse(predicted_classAR2_TR == 3, 1, 0)
dat_roc_tr_AR2$T4_pred_AR2 <- ifelse(predicted_classAR2_TR == 4, 1, 0)

#micro value training data = .7675
rocfit.full_tr_AR2<- multi_roc(dat_roc_tr_AR2)
rocfit.full_tr_AR2$AUC

#SENSITIVITIES, SPECIFICITIES, AND AUC TESTING DATA - BESt ADJ R^2 MODEL
dat_roc_te_AR2 <- data.frame(T1_true = numeric(705),T2_true= numeric(705),T3_true= numeric(705),T4_true= numeric(705),T1_pred_AR2= numeric(705),T2_pred_AR2= numeric(705),T3_pred_AR2= numeric(705),T4_pred_AR2= numeric(705))
#creates data frame in form needed for multi_roc function
dat_roc_te_AR2$T1_true <- ifelse(dat.te$Target == 1, 1, 0)
dat_roc_te_AR2$T2_true <- ifelse(dat.te$Target == 2, 1, 0)
dat_roc_te_AR2$T3_true <- ifelse(dat.te$Target == 3, 1, 0)
dat_roc_te_AR2$T4_true <- ifelse(dat.te$Target == 4, 1, 0)
dat_roc_te_AR2$T1_pred_AR2 <- ifelse(predicted_classAR2_TE == 1, 1, 0)
dat_roc_te_AR2$T2_pred_AR2 <- ifelse(predicted_classAR2_TE == 2, 1, 0)
dat_roc_te_AR2$T3_pred_AR2 <- ifelse(predicted_classAR2_TE == 3, 1, 0)
dat_roc_te_AR2$T4_pred_AR2 <- ifelse(predicted_classAR2_TE == 4, 1, 0)

#micro value testing data = .7484
rocfit.full_te_AR2<- multi_roc(dat_roc_te_AR2)
rocfit.full_te_AR2$AUC



#BEST BIC MODEL
summary.out$which[12,] 

#ACCURACY OF TRAINING DATA = .6944
mod.bic.tr <- multinom(formula = Target ~ tamviv_sqrt + cielorazo + GasOrElectric + etecho1 + dis + hogar_mayor + edjefe + meaneduc + television + qmobilephone + area1 + depend, data = dat.tr)
predicted_classBIC_TR <- predict(mod.bic.tr, type="class")
caret::confusionMatrix(as.factor(predicted_classBIC_TR),as.factor(dat.tr$Target))

#ACCURACY OF Testing DATA = .6567
mod.bic.te <- multinom(formula = Target ~ tamviv_sqrt + cielorazo + GasOrElectric + etecho1 + dis + hogar_mayor + edjefe + meaneduc + television + qmobilephone + area1 + depend, data = dat.te)
predicted_classBIC_TE <- predict(mod.bic.te, type="class")
caret::confusionMatrix(as.factor(predicted_classBIC_TE),as.factor(dat.te$Target))

#SENSITIVITIES, SPECIFICITIES, AND AUC TRAINING DATA - BEST ADJ R^2 MODEL
dat_roc_tr_BIC <- data.frame(T1_true = numeric(2114),T2_true= numeric(2114),T3_true= numeric(2114),T4_true= numeric(2114),T1_pred_BIC= numeric(2114),T2_pred_BIC= numeric(2114),T3_pred_BIC= numeric(2114),T4_pred_BIC= numeric(2114))
#creates data frame in form needed for multi_roc function
dat_roc_tr_BIC$T1_true <- ifelse(dat.tr$Target == 1, 1, 0)
dat_roc_tr_BIC$T2_true <- ifelse(dat.tr$Target == 2, 1, 0)
dat_roc_tr_BIC$T3_true <- ifelse(dat.tr$Target == 3, 1, 0)
dat_roc_tr_BIC$T4_true <- ifelse(dat.tr$Target == 4, 1, 0)
dat_roc_tr_BIC$T1_pred_BIC <- ifelse(predicted_classBIC_TR == 1, 1, 0)
dat_roc_tr_BIC$T2_pred_BIC <- ifelse(predicted_classBIC_TR == 2, 1, 0)
dat_roc_tr_BIC$T3_pred_BIC <- ifelse(predicted_classBIC_TR == 3, 1, 0)
dat_roc_tr_BIC$T4_pred_BIC <- ifelse(predicted_classBIC_TR == 4, 1, 0)

#micro value training data = .7649
rocfit.full_tr_BIC<- multi_roc(dat_roc_tr_BIC)
rocfit.full_tr_BIC$AUC

#SENSITIVITIES, SPECIFICITIES, AND AUC TESTING DATA - BESt ADJ R^2 MODEL
dat_roc_te_BIC <- data.frame(T1_true = numeric(705),T2_true= numeric(705),T3_true= numeric(705),T4_true= numeric(705),T1_pred_BIC= numeric(705),T2_pred_BIC= numeric(705),T3_pred_BIC= numeric(705),T4_pred_BIC= numeric(705))
#creates data frame in form needed for multi_roc function
dat_roc_te_BIC$T1_true <- ifelse(dat.te$Target == 1, 1, 0)
dat_roc_te_BIC$T2_true <- ifelse(dat.te$Target == 2, 1, 0)
dat_roc_te_BIC$T3_true <- ifelse(dat.te$Target == 3, 1, 0)
dat_roc_te_BIC$T4_true <- ifelse(dat.te$Target == 4, 1, 0)
dat_roc_te_BIC$T1_pred_BIC <- ifelse(predicted_classBIC_TE == 1, 1, 0)
dat_roc_te_BIC$T2_pred_BIC <- ifelse(predicted_classBIC_TE == 2, 1, 0)
dat_roc_te_BIC$T3_pred_BIC <- ifelse(predicted_classBIC_TE == 3, 1, 0)
dat_roc_te_BIC$T4_pred_BIC <- ifelse(predicted_classBIC_TE == 4, 1, 0)

#micro value testing data = .7408
rocfit.full_te_BIC<- multi_roc(dat_roc_te_BIC)
rocfit.full_te_BIC$AUC

```

```{r}
#ORDINAL MODELS - 

library(MASS)
library(ordinal)
library(erer)
dat.tr$Target_ord <- ordered(dat.tr$Target, levels = c(1,2,3,4))
dat.te$Target_ord <- ordered(dat.te$Target, levels = c(1,2,3,4))
ord<-clm(formula= (Target_ord ~ .), data= dat.tr)
summary(ord)

#ACCURACY of ordinal model #1 (training) =.6944
predicted_class<- predict (ord, dat.tr, type = "class")
predicted_class<- ordered(predicted_class$fit, levels = c(1,2,3,4))
cm_ols <- table(predicted_class, dat.tr$Target)
print(cm_ols)
Accuracytr <- sum(diag(cm_ols))/sum(cm_ols)
Accuracytr

#ACCURACY of ordinal model #1 (testing) = .6496
predicted_class<- predict (ord, dat.te, type = "class")
predicted_class<- ordered(predicted_class$fit, levels = c(1,2,3,4))
cm_ols <- table(predicted_class, dat.te$Target)
print(cm_ols)
Accuracyte <- sum(diag(cm_ols))/sum(cm_ols)
Accuracyte

ord2 <- clm(formula = (Target_ord ~ v18q1 + tamviv + CementorBetter + cielorazo + GasOrElectric + etecho1 + dis + hogar_mayor + edjefe + meaneduc + television + qmobilephone + area1 + depend), data = dat.tr)
summary(ord2)

#ACCURACY of ordinal model #2 (training) =.6939
predicted_class<- predict (ord2, dat.tr, type = "class")
predicted_class<- ordered(predicted_class$fit, levels = c(1,2,3,4))
cm_ols2 <- table(predicted_class, dat.tr$Target)
print(cm_ols2)
Accuracytr2 <- sum(diag(cm_ols2))/sum(cm_ols2)
Accuracytr2

#ACCURACY of ordinal model #2 (testing) = .6440
predicted_class<- predict (ord2, dat.te, type = "class")
predicted_class<- ordered(predicted_class$fit, levels = c(1,2,3,4))
cm_ols <- table(predicted_class, dat.te$Target)
print(cm_ols)
Accuracyte <- sum(diag(cm_ols))/sum(cm_ols)
Accuracyte
```

```{r}
#SVM (Support Vector Machines) Model 
library(e1071)

# Accuracy of training data = .9972
modelsvm_tr <- svm(Target ~ ., data=dat.tr, gamma = .7, cost = 10)
summary(modelsvm_tr)
predicted_classSVM_TR <- predict(modelsvm_tr, type="class")
caret::confusionMatrix(as.factor(predicted_classSVM_TR),as.factor(dat.tr$Target))

# Accuracy of testing data = .9972
modelsvm_te <- svm(Target ~ ., data=dat.te, gamma = .7, cost = 10)
summary(modelsvm_te)
predicted_classSVM_TE <- predict(modelsvm_te, type="class")
caret::confusionMatrix(as.factor(predicted_classSVM_TE),as.factor(dat.te$Target))

#SENSITIVITIES, SPECIFICITIES, AND AUC TRAINING DATA - BEST ADJ R^2 MODEL
dat_roc_tr_SVM <- data.frame(T1_true = numeric(2114),T2_true= numeric(2114),T3_true= numeric(2114),T4_true= numeric(2114),T1_pred_SVM = numeric(2114),T2_pred_SVM = numeric(2114),T3_pred_SVM = numeric(2114),T4_pred_SVM = numeric(2114))
#creates data frame in form needed for multi_roc function
dat_roc_tr_SVM$T1_true <- ifelse(dat.tr$Target == 1, 1, 0)
dat_roc_tr_SVM$T2_true <- ifelse(dat.tr$Target == 2, 1, 0)
dat_roc_tr_SVM$T3_true <- ifelse(dat.tr$Target == 3, 1, 0)
dat_roc_tr_SVM$T4_true <- ifelse(dat.tr$Target == 4, 1, 0)
dat_roc_tr_SVM$T1_pred_SVM <- ifelse(predicted_classSVM_TR == 1, 1, 0)
dat_roc_tr_SVM$T2_pred_SVM <- ifelse(predicted_classSVM_TR == 2, 1, 0)
dat_roc_tr_SVM$T3_pred_SVM <- ifelse(predicted_classSVM_TR == 3, 1, 0)
dat_roc_tr_SVM$T4_pred_SVM <- ifelse(predicted_classSVM_TR == 4, 1, 0)

#micro value training data = .9974
rocfit.full_tr_SVM<- multi_roc(dat_roc_tr_SVM)
rocfit.full_tr_SVM$AUC

#SENSITIVITIES, SPECIFICITIES, AND AUC TESTING DATA - BESt ADJ R^2 MODEL
dat_roc_te_SVM <- data.frame(T1_true = numeric(705),T2_true= numeric(705),T3_true= numeric(705),T4_true= numeric(705),T1_pred_SVM= numeric(705),T2_pred_SVM= numeric(705),T3_pred_SVM= numeric(705),T4_pred_SVM= numeric(705))
#creates data frame in form needed for multi_roc function
dat_roc_te_SVM$T1_true <- ifelse(dat.te$Target == 1, 1, 0)
dat_roc_te_SVM$T2_true <- ifelse(dat.te$Target == 2, 1, 0)
dat_roc_te_SVM$T3_true <- ifelse(dat.te$Target == 3, 1, 0)
dat_roc_te_SVM$T4_true <- ifelse(dat.te$Target == 4, 1, 0)
dat_roc_te_SVM$T1_pred_SVM <- ifelse(predicted_classSVM_TE == 1, 1, 0)
dat_roc_te_SVM$T2_pred_SVM <- ifelse(predicted_classSVM_TE == 2, 1, 0)
dat_roc_te_SVM$T3_pred_SVM <- ifelse(predicted_classSVM_TE == 3, 1, 0)
dat_roc_te_SVM$T4_pred_SVM <- ifelse(predicted_classSVM_TE == 4, 1, 0)

#micro value testing data = .9980
rocfit.full_te_SVM<- multi_roc(dat_roc_te_SVM)
rocfit.full_te_SVM$AUC
```
```{r}
#TABLE SHOWING ACCURACIES (need to edit)
tab <- as.table(matrix(c(0.672, 0.666, 0.657, 0.649, 0.644, 0.643, 0.634, 0.6434, 0.6434, 0.6241), nrow=10, byrow=TRUE,
            disnames=list(Model=c("Lasso", "Best Subsets", "Best BIC", "Ordinal #1", "Ordinal #2", "Backward Selection", "Full", "Ridge", "Forward Selection", "VIF Based"), Accuracy)))
tab


tab <- matrix(c(0.672, 0.666, 0.657, 0.649, 0.644, 0.643, 0.634, 0.6434, 0.6434, 0.6241, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), nrow=10, byrow=FALSE)
rownames(tab) <-(Model=c("Lasso", "Best Adj R^2", "Best BIC", "Ordinal #1", "Ordinal #2", "Backward Selection", "Full", "Ridge", "Forward Selection", "VIF Based"))
colnames(tab) <- c("Accuracy", "Micro Value")
as.table(tab)

#link to micro explanation 
#https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin
```


