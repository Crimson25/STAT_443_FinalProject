---
title: "Final Project"
author: "Kiera Grant, Braden Barglind, and Colin Fitzpatrick"
date: "12/4/2020"
output:
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
The objective of this study is to determine an appropriate logistic regression model in order to classify individuals into one of four poverty levels. Many social programs have a hard time making sure the right people are given enough aid. Often times the poorest of the population might not be given enough aid because they typically cannot provide the necessary income and expense records to prove that they qualify. Instead, this study will consider a familyâ€™s observable household attributes such as the material of their walls and ceiling, or the assets found in the home, to classify poverty levels. The original dataset contains survey responses from 9,057 individuals with 142 predictor variables. For purposes of this study, only data from the "heads of household" will be used which focuses the data down to 2,819 observations. 

In order to find a sufficient model, all of the predictor variables will be assessed for repetitiveness and skewness and potentially transformed. Relationships between predictor variables and poverty level as well as between the different predictor variables will need to be evaluated. This will help determine any preliminary multicollinearity issues so that these variables can be removed from the dataset early. The data will be split into a training data set as well as a validation data set in order to test the accuracy of our model. A logistic regression model will be created using the training data. The model will then be used to predict the poverty level of samples to determine the effectiveness of the model. The model selection tools will be used to determine if more accuracy is gained through a new model. Next, the classification threshold will be investigated to determine which value optimizes accuracy. The final model will be determined based off of these analyses in hopes to have an appropriate model to classify individuals into a poverty class. 

## Exploring and Transforming the Data
The first thing that we had to take care of, was limiting the amount of variables to a sizable amount.  We then deleted all redundant variables which measured the same things but called by different names.  An example of this is these redundant variables hhsize and tamhog, which both measure the size of the household.  So we are able to get rid of one of them and keep the other.  Another thing we did with the data is to combine some of the terms so that we would have one variable that was now a binomial response. An example of this is, there was a male and female tab, which we are able to remove one of them because it gives redundant information.  Another way we partioned through the data was to get rid of variables based in the percentage of reponses that they had.  For example, one of the identifiers was if the house had a bathroom or not and the probability of houses having a bathroom was .995.  This results in a bad predictor as too many people have a bathroom so it is not a good predictor in that since.  So after those three ideas took place we were left with 34 variables left out of 142.
```{r message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}
library(tidyverse) 
library(ggrepel) 
library(kableExtra) 
library(RColorBrewer) 
library(corrplot) 
library(caret) 
library(e1071) 
library(dominanceanalysis) 
library("readxl")

project_data <-  read_excel("HeadOfHouseHoldFile.xlsx")
head(project_data)

project_data2 <- read_excel("HeadOfHouseHoldFileUpdate.xlsx")
head(project_data2)

project_data_final <- read_excel("FinalChanges.xlsx")
head(project_data_final)

##CLEAN UP DATA
#replaces one variable with the variable that was transformed
project_data_final$tamviv <- project_data_final$tamvivsqrt
names(project_data_final)[3] <- "tamviv_sqrt"

#removes reference variables (and removes copy of transformed variable)
project_data_final <- project_data_final %>% dplyr::select(-c("paredblolad","paredpreb", "energcocinar2", "energcocinar3", "Married/Free Coupled", "div,sep,wid", "single", "parentesco1","tamvivsqrt"))

project_data_final$Target <- as.factor(project_data_final$Target) # sets Target to factor for analyses
apply(is.na(project_data_final), 2, which) #detects NAs in data frame, 3 values in meaneduc (1287, 1400, 1455), 1 value in depend (1287)
project_data_final[is.na(project_data_final)]=0  #replaces NAs with 0, can replace with zero for these categories


##EXPLORING THE DATA - QUANTITATIVE
#Rooms Plot (normal)
roomcounts <- table(project_data$rooms)
barplot(roomcounts,main="Number of Rooms", xlab="Room Counts")

#Number of Tablets Plot (heavy skew right)
tabletscounts <- table(project_data$v18q1)
barplot(tabletscounts,main="Number of Tablets", xlab="Tablet Counts")

#Number of People in Household Plot (skew right)
peoplecounts <- table(project_data$tamviv)
barplot(peoplecounts, main="Number of People in Household", xlab="People Counts")

#Children 0-19 Plot (skew right)
childrencounts <- table(project_data$hogar_nin)
barplot(childrencounts, main="Number of Children 0-19", xlab="Children Counts")

#Number of Adults Plot (small skew right)
adultcounts <- table(project_data$hogar_adul)
barplot(adultcounts, main="Number of Adults", xlab="Adult Counts")

#People 65+ Plot (heavy skew right)
people65counts <- table(project_data$hogar_mayor)
barplot(people65counts, main="People 65+", xlab = "People Counts")

#EdJefe Plot (weird)
edjefecounts <- table(project_data$edjefe)
barplot(edjefecounts, main="Ed Jefe Counts", xlab = "Counts")

#EdJefa Plot (weird)
edjefacounts <- table(project_data$edjefa)
barplot(edjefacounts, main="Ed Jefa Counts", xlab="Counts")

#Mean Education Plot (weird)
meaneducounts <- table(project_data$meaneduc)
barplot(meaneducounts, main="Mean Education", xlab="Counts")

#Overcrowding Plot (weird)
overcrowdcounts <- table(project_data$overcrowding)
barplot(overcrowdcounts, main="Overcrowding", xlab="Counts")

#Number of Dependents (weird)
dependcounts <- table(project_data$depend)
barplot(dependcounts, main="Dependencies", xlab="Counts")


##TRANSFORMATIONS
#Number of people in Household transformation: Square root  (only transformation that showed significant change)
sqrttamviv <- (sqrt(project_data$tamviv))
hist(sqrttamviv)


##EXPLORING RELATIONSHIPS

#Relationships between predictors
quantvars <- c(1,2,3,13,14,15,16,17,18,19,22,25)
dichotomouscategorvars <- c(4,5,6,7,8,9,10,11,20,21,23) #12=marriage status, has 3 levels
categorvars <- c(4,5,6,7,8,9,10,11,12,20,21,23)

#shows top correlated variables
z <-cor(project_data_final[,quantvars])
z[lower.tri(z,diag=TRUE)]=NA 
z2=as.data.frame(as.table(z))  
z3=na.omit(z2) 
z4 <- subset(z3, abs(Freq)> .5) 
correlation_df <- z4[order(-z4$Freq), ]
correlation_df

library(PerformanceAnalytics)
chart.Correlation(project_data_final[,quantvars],histogram = TRUE) #correlations for quantitative variables
chart.Correlation(project_data_final[,dichotomouscategorvars],histogram = TRUE) #correlations for dichotomous categorical variables
chart.Correlation(project_data_final[,categorvars],histogram = TRUE, method = "spearman") #correlations for categorical variables
catvartest<- chisq.test()   #pairwise, double "for" loop

#Relationships between predictors and response variables
library(gridExtra)
##Function for creating bar graphs (of all quantitative variables) by target
graphs <- function(x){
xvar <- unlist(project_data_final[,x])
plot <- project_data_final %>% ggplot(aes(xvar,fill=Target))+ 
  geom_bar() + 
  facet_grid(. ~ Target) +
  xlab(colnames(project_data_final[x]))
return(plot)
}
plot_list <-lapply(quantvars,FUN=graphs)
plot_list


##Function for creating FREQUENCY graphs (of all quantitative variables) by target
freqgraphs <- function(x){
xvar <- unlist(project_data_final[,x])
plot <- project_data_final %>% ggplot(aes(xvar, colour=Target)) + 
  geom_freqpoly(aes(group = Target)) +
  xlab(colnames(project_data_final[x]))
return(plot)
}
freqplot_list <-lapply(quantvars,FUN=freqgraphs)
freqplot_list

```


## The Statistical Model
```{r message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}

#split data into raining and testing set
set.seed(46217921)
train.pov <- sample(1:nrow(project_data_final), floor(.75*nrow(project_data_final)), replace=F)
dat.tr <- project_data_final[train.pov,]
dat.te <- project_data_final[-train.pov,]
head(dat.tr)
table(dat.tr$Target) #.66556 proportions are target 4
table(dat.te$Target) #.626995 proportions are target 4


library(nnet)
library(MLmetrics)
library(compositions)
library(caret)

#Build regression model using training/testing
mod.full <- multinom(Target ~ ., data=dat.tr) #Multinom Function

#gives VIF values of each variable in the full model: want to remove variables with VIF higher than 5-10, for this analyses the following remain after removing higher than 10: v18q1,CementorBetter, cielorazo, epared1, etecho1, eviv1, dis, computer, television, area1
car::vif(mod.full)

#Finds pseudo R^2 value of model
library(DescTools)
PseudoR2(mod.full,"McFadden") # R^2 = .22619

#ACCURACY OF TRAINING DATA - Full Multinomial Model = .702
predicted_classFM_TR <- predict(mod.full,dat.tr)
caret::confusionMatrix(as.factor(predicted_classFM_TR),as.factor(dat.tr$Target))

#ACCURACY OF TESTING DATA - Full Multinomial Model= .6397
predicted_classFM_TE <- predict(mod.full,dat.te)
caret::confusionMatrix(as.factor(predicted_classFM_TE),as.factor(dat.te$Target))

#SENSITIVITIES, SPECIFICITIES, AND AUC - FUll Multinomial Model
dat_roc_FM_TR<- data.frame(T1_true = numeric(2114),T2_true= numeric(2114),T3_true= numeric(2114),T4_true= numeric(2114),T1_pred_FM= numeric(2114),T2_pred_FM= numeric(2114),T3_pred_FM= numeric(2114),T4_pred_FM= numeric(2114))
#creates data frame in form needed for multi_roc function
dat_roc_FM_TR$T1_true <- ifelse(dat.tr$Target == 1, 1, 0)
dat_roc_FM_TR$T2_true <- ifelse(dat.tr$Target == 2, 1, 0)
dat_roc_FM_TR$T3_true <- ifelse(dat.tr$Target == 3, 1, 0)
dat_roc_FM_TR$T4_true <- ifelse(dat.tr$Target == 4, 1, 0)
dat_roc_FM_TR$T1_pred_FM <- ifelse(predicted_classFM_TR == 1, 1, 0)
dat_roc_FM_TR$T2_pred_FM <- ifelse(predicted_classFM_TR == 2, 1, 0)
dat_roc_FM_TR$T3_pred_FM <- ifelse(predicted_classFM_TR == 3, 1, 0)
dat_roc_FM_TR$T4_pred_FM <- ifelse(predicted_classFM_TR == 4, 1, 0)

rocfit.full_FM_TR <- multi_roc(dat_roc_FM_TR)
rocfit.full_FM_TR$AUC


##Multinomial Model #2
mod.vif_under_10 <-multinom(Target~v18q1 + CementorBetter + cielorazo + epared1 + etecho1 + eviv1 + dis + computer + television + area1, data = dat.tr)

car::vif(mod.vif_under_10)
PseudoR2(mod.vif_under_10,"all") # R^2 = .1026

#ACCURACY OF TRAINING DATA - VIF Under 10 Multinomial Model = .6712
predicted_classFM2_TR <- predict(mod.vif_under_10,dat.tr)
caret::confusionMatrix(as.factor(predicted_classFM2_TR),as.factor(dat.tr$Target))

#ACCURACY OF TESTING DATA - VIF Under 10 Multinomial Model= .6241
predicted_classFM2_TE <- predict(mod.vif_under_10,dat.te)
caret::confusionMatrix(as.factor(predicted_classFM2_TE),as.factor(dat.te$Target))

#SENSITIVITIES, SPECIFICITIES, AND AUC - Multinomial Model #2
dat_roc_FM2_TR<- data.frame(T1_true = numeric(2114),T2_true= numeric(2114),T3_true= numeric(2114),T4_true= numeric(2114),T1_pred_FM2= numeric(2114),T2_pred_FM2= numeric(2114),T3_pred_FM2= numeric(2114),T4_pred_FM2= numeric(2114))
#creates data frame in form needed for multi_roc function
dat_roc_FM2_TR$T1_true <- ifelse(dat.tr$Target == 1, 1, 0)
dat_roc_FM2_TR$T2_true <- ifelse(dat.tr$Target == 2, 1, 0)
dat_roc_FM2_TR$T3_true <- ifelse(dat.tr$Target == 3, 1, 0)
dat_roc_FM2_TR$T4_true <- ifelse(dat.tr$Target == 4, 1, 0)
dat_roc_FM2_TR$T1_pred_FM <- ifelse(predicted_classFM2_TR == 1, 1, 0)
dat_roc_FM2_TR$T2_pred_FM <- ifelse(predicted_classFM2_TR == 2, 1, 0)
dat_roc_FM2_TR$T3_pred_FM <- ifelse(predicted_classFM2_TR == 3, 1, 0)
dat_roc_FM2_TR$T4_pred_FM <- ifelse(predicted_classFM2_TR == 4, 1, 0)

rocfit.full_FM2_TR <- multi_roc(dat_roc_FM2_TR)
rocfit.full_FM2_TR$AUC
```

```{r}
#Cumulative Logit Model - Reflects ordering - NOT WORKING
library(VGAM)
fit.adj <- vglm(Target ~ .,family=cumulative(parallel=TRUE), data=dat.tr)
coef(fit.adj)
predict.te <- predict(fit.adj,dat.te, type = "response")

#ACCURACY OF TRAINING DATA =
predicted_classVGLM <- predict(fit.adj,dat.tr)
caret::confusionMatrix(as.factor(predicted_classVGLM),as.factor(dat.tr$Target))

#ACCURACY OF TESTING DATA =
predicted_classVGLM <- predict(mod.full,dat.te)
caret::confusionMatrix(as.factor(predicted_classML),as.factor(dat.te$Target))
```

```{r}
#LASSO MODEL  - suggests to take out hogar_nin and edjefa
library(glmnet)
xx <- model.matrix(Target~., dat.tr)
yy <- as.integer(dat.tr$Target) #packages requires this to be numeric
lasso.out <- cv.glmnet(xx, yy, alpha=1, family = "multinomial", type.multinomial = "grouped", type.measure="class")  #do we need to set this family to multinomial?
coef(lasso.out, s=lasso.out$lambda.min)

#ACCURACY OF TRAINING DATA = .7001
mod.lasso.tr <- multinom(formula = Target ~ rooms + v18q1 + tamviv + CementorBetter + cielorazo + GasOrElectric + elimbasu1 + epared1 + etecho1 + eviv1 + dis + comMSS + hogar_adul + hogar_mayor + edjefe + meaneduc + overcrowding + computer + television + qmobilephone + area1 + depend, data = dat.tr)
predicted_classLM_TR <- predict(mod.lasso.tr, type="class")
acc_LM_TR <- caret::confusionMatrix(as.factor(predicted_classLM_TR),as.factor(dat.tr$Target))

#ACCURACY OF Testing DATA = .6695
mod.lasso.te <- multinom(formula = Target ~ rooms + v18q1 + tamviv + CementorBetter + cielorazo + GasOrElectric + elimbasu1 + epared1 + etecho1 + eviv1 + dis + comMSS + hogar_adul + hogar_mayor + edjefe + meaneduc + overcrowding + computer + television + qmobilephone + area1 + depend, data = dat.te)
predicted_classLM_TE <- predict(mod.lasso.te, type="class")
acc_LM_TE <- caret::confusionMatrix(as.factor(predicted_classLM_TE),as.factor(dat.te$Target))

#SENSITIVITIES, SPECIFICITIES, AND AUC of LASSO
dat_roc_te_LM <- data.frame(T1_true = numeric(705),T2_true= numeric(705),T3_true= numeric(705),T4_true= numeric(705),T1_pred_LM= numeric(705),T2_pred_LM= numeric(705),T3_pred_LM= numeric(705),T4_pred_LM= numeric(705))
#creates data frame in form needed for multi_roc function
dat_roc_te_LM$T1_true <- ifelse(dat.te$Target == 1, 1, 0)
dat_roc_te_LM$T2_true <- ifelse(dat.te$Target == 2, 1, 0)
dat_roc_te_LM$T3_true <- ifelse(dat.te$Target == 3, 1, 0)
dat_roc_te_LM$T4_true <- ifelse(dat.te$Target == 4, 1, 0)
dat_roc_te_LM$T1_pred_LM <- ifelse(predicted_classLM_TE == 1, 1, 0)
dat_roc_te_LM$T2_pred_LM <- ifelse(predicted_classLM_TE == 2, 1, 0)
dat_roc_te_LM$T3_pred_LM <- ifelse(predicted_classLM_TE == 3, 1, 0)
dat_roc_te_LM$T4_pred_LM <- ifelse(predicted_classLM_TE == 4, 1, 0)

rocfit.full_te_LM<- multi_roc(dat_roc_te_LM)
rocfit.full_te_LM$AUC
```

```{r}
#Ridge MODEL  - doesn't suggest to take any variables out?
xxR <- model.matrix(Target~., dat.tr)
yyR <- as.integer(dat.tr$Target) #packages requires this to be numeric
ridge.out <- cv.glmnet(xxR, yyR, alpha=0, type.measure="class") 
coef(ridge.out, s=ridge.out$lambda.min)

#same accuracies as full multinomial model?
#Training Accuracy = .702
#Testing Accuracy = .6397

```

```{r}
#Backward Selection - significant variables in equation below
#multinom(formula = Target ~ v18q1 + tamviv + CementorBetter + cielorazo + GasOrElectric + etecho1 + eviv1 + dis + hogar_mayor + edjefe + meaneduc + television + qmobilephone + area1 + depend, data = dat.tr)
mod.back <- step(mod.full,  direction="backward", trace=0)
summary(mod.back)

#ACCURACY OF TRAINING DATA = .6991
predicted_classBS_TR <- predict(mod.back,dat.tr)
caret::confusionMatrix(as.factor(predicted_classBS_TR),as.factor(dat.tr$Target))

#ACCURACY OF TESTING DATA = .6383
predicted_classBS_TE <- predict(mod.back,dat.te)
caret::confusionMatrix(as.factor(predicted_classBS_TE),as.factor(dat.te$Target))
```

```{r}
#Forward Selection - didn't remove any variables? Equation below
#multinom(formula = Target ~ rooms + v18q1 + tamviv + CementorBetter + cielorazo + GasOrElectric + elimbasu1 + epared1 + etecho1 + eviv1 + dis + comMSS + hogar_nin + hogar_adul + hogar_mayor + edjefe + edjefa + meaneduc + overcrowding + computer + television + qmobilephone + area1 + depend, data = dat.tr)
mod.forward <- step(mod.full, direction="forward", trace=0)
test <- predict(mod.forward, type="class")
summary(mod.forward)

#ACCURACY OF TRAINING DATA = .702
predicted_classFS_TR <- predict(mod.forward,dat.tr)
caret::confusionMatrix(as.factor(predicted_classFS_TR),as.factor(dat.tr$Target))

#ACCURACY OF TESTING DATA = .6397
predicted_classFS_TE <- predict(mod.forward,dat.te)
caret::confusionMatrix(as.factor(predicted_classFS_TE),as.factor(dat.te$Target))

```
```{r}
#ORDINAL MODELS - 

library(MASS)
library(ordinal)
library(erer)
dat.tr$Target_ord <- ordered(dat.tr$Target, levels = c(1,2,3,4))
dat.te$Target_ord <- ordered(dat.te$Target, levels = c(1,2,3,4))
ord<-clm(formula= (Target_ord ~ .), data= dat.tr)
summary(ord)

#ACCURACY of ordinal model #1 (training) =.6944
predicted_class<- predict (ord, dat.tr, type = "class")
predicted_class<- ordered(predicted_class$fit, levels = c(1,2,3,4))
cm_ols <- table(predicted_class, dat.tr$Target)
print(cm_ols)
Accuracytr <- sum(diag(cm_ols))/sum(cm_ols)
Accuracytr

#ACCURACY of ordinal model #1 (testing) = .6496
predicted_class<- predict (ord, dat.te, type = "class")
predicted_class<- ordered(predicted_class$fit, levels = c(1,2,3,4))
cm_ols <- table(predicted_class, dat.te$Target)
print(cm_ols)
Accuracyte <- sum(diag(cm_ols))/sum(cm_ols)
Accuracyte

ord2 <- clm(formula = (Target_ord ~ v18q1 + tamviv + CementorBetter + cielorazo + GasOrElectric + etecho1 + dis + hogar_mayor + edjefe + meaneduc + television + qmobilephone + area1 + depend), data = dat.tr)
summary(ord2)

#ACCURACY of ordinal model #2 (training) =.6939
predicted_class<- predict (ord2, dat.tr, type = "class")
predicted_class<- ordered(predicted_class$fit, levels = c(1,2,3,4))
cm_ols2 <- table(predicted_class, dat.tr$Target)
print(cm_ols2)
Accuracytr2 <- sum(diag(cm_ols2))/sum(cm_ols2)
Accuracytr2

#ACCURACY of ordinal model #2 (testing) = .6440
predicted_class<- predict (ord2, dat.te, type = "class")
predicted_class<- ordered(predicted_class$fit, levels = c(1,2,3,4))
cm_ols <- table(predicted_class, dat.te$Target)
print(cm_ols)
Accuracyte <- sum(diag(cm_ols))/sum(cm_ols)
Accuracyte
```

#TABLE SHOWING ACCURACIES (need to edit)





